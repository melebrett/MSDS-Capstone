{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import datetime\n",
    "import json\n",
    "import random\n",
    "\n",
    "import bs4 as bs\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from splinter import Browser\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up browser (use headless when deployed)\n",
    "url = \"https://www.pgatour.com/stats/detail/109\"\n",
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "# chop = webdriver.ChromeOptions()\n",
    "# chop.add_extension('adblock.crx')\n",
    "browser = Browser('chrome', **executable_path, headless = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.visit(url)\n",
    "time.sleep(1)\n",
    "browser.find_by_value('Time Period').click()\n",
    "time.sleep(1)\n",
    "browser.find_by_value('Tournament Only').click()\n",
    "time.sleep(1)\n",
    "\n",
    "# scrape\n",
    "soup = BeautifulSoup(browser.html, 'html.parser')\n",
    "# find the div with class like \"menu-list\"\n",
    "menu_lists = soup.find_all(\"div\", class_ = lambda class_: class_ and \"menu-list\" in class_)\n",
    "\n",
    "seasons = []\n",
    "season_list = menu_lists[0].find_all(\"button\")\n",
    "for season in season_list:\n",
    "    seasons.append(season.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetTourneyMoneyFromSoup(soup):\n",
    "    # find the table in the html\n",
    "    tab = soup.find(\"table\")\n",
    "\n",
    "    # get the table headers\n",
    "    cols = []\n",
    "    headers = tab.find(\"thead\").find_all(\"th\")\n",
    "    for header in headers:\n",
    "        cols.append(header.text)\n",
    "\n",
    "    # get the table rows\n",
    "    tab_rows = tab.find_all(\"tr\")\n",
    "\n",
    "    # collect the data\n",
    "    all_data = []\n",
    "    for row in tab_rows:\n",
    "\n",
    "        # get the table data tags\n",
    "        tds = row.find_all(\"td\")\n",
    "        # if no data, skip\n",
    "        if len(tds) == 0:\n",
    "            continue\n",
    "        else:\n",
    "            try:\n",
    "                row_data = []\n",
    "                for col in range(len(cols)):\n",
    "                    row_data.append(tds[col].text)\n",
    "                # create dictionary with cols mapped to row_data\n",
    "                row_dict = dict(zip(cols, row_data))\n",
    "                all_data.append(row_dict)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    df = pd.DataFrame(all_data)\n",
    "\n",
    "    tourney_tag = soup.find(\"p\", text = lambda text: text and text == \"Tournament\")\n",
    "    tourney_tags = tourney_tag.find_parent(\"div\").find_parent(\"div\").find_all(\"p\")\n",
    "    tournament = tourney_tags[1].text\n",
    "\n",
    "    season_tag = soup.find(\"p\", text = lambda text: text and text == \"Season\")\n",
    "    season_tags = season_tag.find_parent(\"div\").find_parent(\"div\").find_all(\"p\")\n",
    "    season = season_tags[1].text\n",
    "\n",
    "    df[\"Tournament\"] = tournament\n",
    "    df[\"Season\"] = season\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-2023\n",
      "2021-2022\n",
      "2020-2021\n",
      "2019-2020\n",
      "2018-2019\n",
      "2017-2018\n",
      "2016-2017\n",
      "2015-2016\n",
      "2014-2015\n",
      "2013-2014\n",
      "2013\n",
      "2012\n",
      "ERROR: could not get data for THE HONDA CLASSIC\n",
      "2011\n"
     ]
    }
   ],
   "source": [
    "seasons = seasons[:13]\n",
    "all_dfs = []\n",
    "counter = 0\n",
    "for season in seasons:\n",
    "    print(season)\n",
    "\n",
    "    try:\n",
    "        if counter > 0:\n",
    "            # click the dropdown for the desired season\n",
    "            browser.find_by_value('Season').click()\n",
    "            browser.find_by_value(season).click()\n",
    "            time.sleep(5)\n",
    "            \n",
    "            # scrape the page\n",
    "            soup = BeautifulSoup(browser.html, 'html.parser')\n",
    "            menu_lists = soup.find_all(\"div\", class_ = lambda class_: class_ and \"menu-list\" in class_)\n",
    "            \n",
    "        # find all the tournaments\n",
    "        tournaments = []\n",
    "        tourney_list = menu_lists[2].find_all(\"button\")\n",
    "        for element in tourney_list:\n",
    "            tournaments.append(element.text)\n",
    "            \n",
    "        # loop through each tournament and scrape the table\n",
    "        for tourney in tournaments:\n",
    "            try:\n",
    "                # print(f\"getting data for {tourney.upper()}...\")\n",
    "                \n",
    "                browser.find_by_value('Tournament').click()\n",
    "                browser.find_by_value(tourney).click()\n",
    "                time.sleep(5)\n",
    "\n",
    "                soup = BeautifulSoup(browser.html, 'html.parser')\n",
    "\n",
    "                df = GetTourneyMoneyFromSoup(soup)\n",
    "\n",
    "                all_dfs.append(df)\n",
    "            except:\n",
    "                print(f\"ERROR: could not get data for {tourney.upper()}\")\n",
    "    except:\n",
    "        print(f\"ERROR: could not scrape {season}\")\n",
    "    \n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.concat(all_dfs)\n",
    "# turn money column into numeric\n",
    "final_df[\"Money\"] = final_df[\"Money\"].str.replace(\"$\", \"\").str.replace(\",\", \"\").astype(int)\n",
    "# final_df.to_csv(\"earnings.csv\")\n",
    "# final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-13 22:05:35,043 INFO sqlalchemy.engine.Engine select pg_catalog.version()\n",
      "2023-07-13 22:05:35,043 INFO sqlalchemy.engine.Engine [raw sql] {}\n",
      "2023-07-13 22:05:35,066 INFO sqlalchemy.engine.Engine select current_schema()\n",
      "2023-07-13 22:05:35,066 INFO sqlalchemy.engine.Engine [raw sql] {}\n",
      "2023-07-13 22:05:35,096 INFO sqlalchemy.engine.Engine show standard_conforming_strings\n",
      "2023-07-13 22:05:35,097 INFO sqlalchemy.engine.Engine [raw sql] {}\n",
      "2023-07-13 22:05:35,137 INFO sqlalchemy.engine.Engine select relname from pg_class c join pg_namespace n on n.oid=c.relnamespace where pg_catalog.pg_table_is_visible(c.oid) and relname=%(name)s\n",
      "2023-07-13 22:05:35,137 INFO sqlalchemy.engine.Engine [generated in 0.00074s] {'name': 'earnings'}\n",
      "2023-07-13 22:05:35,162 INFO sqlalchemy.engine.Engine \n",
      "CREATE TABLE earnings (\n",
      "\t\"Rank\" TEXT, \n",
      "\t\"Player\" TEXT, \n",
      "\t\"Money\" INTEGER, \n",
      "\t\"Tournament\" TEXT, \n",
      "\t\"Season\" TEXT\n",
      ")\n",
      "\n",
      "\n",
      "2023-07-13 22:05:35,163 INFO sqlalchemy.engine.Engine [no key 0.00079s] {}\n",
      "2023-07-13 22:05:35,179 INFO sqlalchemy.engine.Engine COMMIT\n",
      "2023-07-13 22:05:35,442 INFO sqlalchemy.engine.Engine INSERT INTO earnings (\"Rank\", \"Player\", \"Money\", \"Tournament\", \"Season\") VALUES (%(Rank)s, %(Player)s, %(Money)s, %(Tournament)s, %(Season)s)\n",
      "2023-07-13 22:05:35,443 INFO sqlalchemy.engine.Engine [generated in 0.21286s] ({'Rank': '1', 'Player': 'Sepp Straka', 'Money': 1332000, 'Tournament': 'John Deere Classic', 'Season': '2022-2023'}, {'Rank': '2', 'Player': 'Alex Smalley', 'Money': 658600, 'Tournament': 'John Deere Classic', 'Season': '2022-2023'}, {'Rank': '2', 'Player': 'Brendon Todd', 'Money': 658600, 'Tournament': 'John Deere Classic', 'Season': '2022-2023'}, {'Rank': '4', 'Player': 'Ludvig Aberg', 'Money': 333000, 'Tournament': 'John Deere Classic', 'Season': '2022-2023'}, {'Rank': '4', 'Player': 'Adam Schenk', 'Money': 333000, 'Tournament': 'John Deere Classic', 'Season': '2022-2023'}, {'Rank': '6', 'Player': 'Lucas Glover', 'Money': 218036, 'Tournament': 'John Deere Classic', 'Season': '2022-2023'}, {'Rank': '6', 'Player': 'Mark Hubbard', 'Money': 218036, 'Tournament': 'John Deere Classic', 'Season': '2022-2023'}, {'Rank': '6', 'Player': 'Denny McCarthy', 'Money': 218036, 'Tournament': 'John Deere Classic', 'Season': '2022-2023'}  ... displaying 10 of 38975 total bound parameter sets ...  {'Rank': '30', 'Player': 'Rocco Mediate', 'Money': 56000, 'Tournament': 'Hyundai Tournament of Champions', 'Season': '2011'}, {'Rank': '31', 'Player': 'Derek Lamely', 'Money': 55000, 'Tournament': 'Hyundai Tournament of Champions', 'Season': '2011'})\n",
      "2023-07-13 22:05:36,882 INFO sqlalchemy.engine.Engine COMMIT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pyodbc\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from sqlalchemy.engine import URL\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "import struct\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "PORT = os.getenv(\"PORT\")\n",
    "PWD = os.getenv(\"PWD\")\n",
    "HOST = os.getenv(\"HOST\")\n",
    "USER = os.getenv(\"USER\")\n",
    "DB = os.getenv(\"DB\")\n",
    "\n",
    "def db_connect():\n",
    "\n",
    "    # construct connection string\n",
    "    connection_string = f\"postgresql+psycopg2://{USER}:{PWD}@{HOST}:{PORT}/{DB}\"\n",
    "    # print(connection_string)\n",
    "    try:\n",
    "        engine = create_engine(connection_string, echo=True)\n",
    "        conn = engine.connect()\n",
    "    except pyodbc.InterfaceError as ex:\n",
    "            raise ex\n",
    "        \n",
    "    return conn\n",
    "\n",
    "def write_to_db(df, table_name, append=False):\n",
    "    conn = db_connect()\n",
    "    if append:\n",
    "        df.to_sql(table_name, conn, if_exists='append', index=False)\n",
    "    else:\n",
    "        df.to_sql(table_name, conn, if_exists='replace', index=False)\n",
    "    conn.close()\n",
    "\n",
    "\n",
    "write_to_db(final_df, \"earnings\", append=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
